{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib import pyplot as plt\n",
    "from e2e.deeplabv3plus import DeepLabV3plus\n",
    "from utils.visual import vis_segmentation\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "NUM_CLASS = 55\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "LEARN_RT = 1e-5\n",
    "BATCH_SIZE = 7\n",
    "CRF = True\n",
    "INFER_ITER = 17\n",
    "INFER_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3plus(weights=None, input_shape=(IMG_SIZE, IMG_SIZE, 3), classes=NUM_CLASS, backbone='xception',\n",
    "                              OS=16, activation=None, use_crf=CRF, osi_iter=INFER_ITER, infer_rate=INFER_RATE)\n",
    "rectified_adam = tfa.optimizers.RectifiedAdam(\n",
    "            lr=3e-5,\n",
    "            total_steps=10000,\n",
    "            warmup_proportion=0.2,\n",
    "            min_lr=LEARN_RT,\n",
    "            epsilon=1e-08\n",
    "        )\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=[tf.keras.metrics.MeanIoU(NUM_CLASS, name='mIoU'), 'sparse_categorical_accuracy'],\n",
    "                      optimizer=rectified_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd33ad29520>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dir = \"logs/segmentation/20210516-193213-lr_1e-05-bs_3-NoDecay-flipped_True-rotate_True-stuff512-adam-crf\"\n",
    "model.load_weights(weight_dir + \"/006.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(record):\n",
    "    img, mask, seg_ids, seg_lbs = record['image'], record['panoptic_image'], record['panoptic_objects']['id'], \\\n",
    "                                  record['panoptic_objects']['label']\n",
    "    img = tf.image.resize(img, size=[IMG_SIZE, IMG_SIZE]) / 255.  # normalize to [0, 1] better than [-1, 1]!\n",
    "\n",
    "    mask, seg_ids, seg_lbs = tf.cast(mask, tf.int32), tf.cast(seg_ids, tf.int32), tf.cast(seg_lbs, tf.int32)\n",
    "    mask = mask[:, :, 0] + mask[:, :, 1] * 256 + mask[:, :, 2] * 256 ** 2\n",
    "    # mask = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(seg_ids, seg_lbs) + 1), 0).lookup(mask)\n",
    "    for i in range(len(seg_ids)):\n",
    "        mask = tf.where(mask == seg_ids[i], -(seg_lbs[i] + 1), mask)\n",
    "    mask = tf.abs(mask)\n",
    "    mask = tf.where(tf.math.logical_and(mask > 0, mask < 81), 1, mask)  # mark all things as 1\n",
    "    mask = tf.where(mask > 80, mask - 79, mask)  # offset stuff label start from 2\n",
    "\n",
    "    # resize to 512 with Nearest neighbor interpolation\n",
    "    mask = tf.image.resize(tf.expand_dims(mask, -1), size=[IMG_SIZE, IMG_SIZE], method='nearest')\n",
    "    \n",
    "    return img, tf.squeeze(mask, -1)\n",
    "\n",
    "def get_data(name='coco/2017_panoptic', split='train+validation'):\n",
    "    dataset = tfds.load(name, split=split, shuffle_files=True, data_dir=\"/data/hao/vision/\")\n",
    "    dataset = dataset.shuffle(buffer_size=5000, reshuffle_each_iteration=True) \\\n",
    "        .map(get_xy, num_parallel_calls=AUTOTUNE) \\\n",
    "        .batch(BATCH_SIZE, drop_remainder=False) \\\n",
    "        .prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata = get_data(name='coco/2017_panoptic', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715/715 [==============================] - 2807s 4s/step - loss: 186.0923 - mIoU: 0.0071 - sparse_categorical_accuracy: 0.2536\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(validata, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = validata.take(3)\n",
    "for k, (imgs, mask) in enumerate(samples):\n",
    "    res = model.predict_on_batch(imgs)\n",
    "    for img, rs in zip(imgs, res):\n",
    "        vis_segmentation(tf.cast(img * 255, tf.uint8), tf.argmax(rs, -1).numpy(), ds='coco-stuff') #, save_name=f'tmp/val/internet-e77/res/{k}.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
